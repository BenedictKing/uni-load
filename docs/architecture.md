# uni-load 系统架构设计

## 概述

uni-load 是一个 AI 站点自动配置工具，作为连接 uni-api 与 gpt-load 的中间桥梁，实现第三方 AI 站点的快速集成和负载均衡配置。

## 系统架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                        uni-load 架构图                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────┐    HTTP API    ┌─────────────────────────────┐ │
│  │   Web UI     │ ──────────────▶│      Express Server        │ │
│  │  (Frontend)  │                │   (TypeScript/Node.js)     │ │
│  └──────────────┘                └─────────────────────────────┘ │
│                                              │                   │
│                                              ▼                   │
│  ┌─────────────────────────────────────────────────────────────┐ │
│  │                   核心服务层                                  │ │
│  ├─────────────────────────────────────────────────────────────┤ │
│  │ gptload.ts    │ models.ts     │ yaml-manager.ts             │ │
│  │ gpt-load 交互 │ 模型获取服务   │ uni-api 配置管理            │ │
│  ├─────────────────────────────────────────────────────────────┤ │
│  │ multi-gptload.ts  │ model-sync.ts │ channel-health.ts       │ │
│  │ 多实例管理        │ 模型同步服务   │ 渠道健康检查            │ │
│  └─────────────────────────────────────────────────────────────┘ │
│                                              │                   │
│                                              ▼                   │
│  ┌─────────────────────────────────────────────────────────────┐ │
│  │                   外部依赖层                                  │ │
│  ├─────────────────────────────────────────────────────────────┤ │
│  │  gpt-load        │  uni-api         │  第三方 AI 站点      │ │
│  │  实例 1,2,3...   │  配置管理         │  OpenAI, Claude...   │ │
│  └─────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
```

## 核心组件

### 1. Express 服务器 (server.ts)
- **职责**: HTTP 请求处理、路由管理、中间件配置
- **端口**: 默认 3002
- **主要功能**:
  - Web UI 静态文件服务
  - API 路由处理
  - CORS 跨域支持
  - 请求参数验证

### 2. 核心服务层

#### gptload.ts - gpt-load 交互服务
- **职责**: 与 gpt-load 实例的所有交互操作
- **主要功能**:
  - 创建和管理分组
  - 代理配置
  - 健康检查
  - 负载均衡配置

#### models.ts - 模型获取服务
- **职责**: 从第三方 AI 站点获取可用模型列表
- **支持格式**: OpenAI API 兼容接口
- **主要功能**:
  - 调用 `/v1/models` 接口
  - 模型列表解析和过滤
  - 错误处理和重试机制

#### yaml-manager.ts - uni-api 配置管理
- **职责**: 管理 uni-api 的 YAML 配置文件
- **主要功能**:
  - 读取和解析 api.yaml
  - 添加新的 provider 配置
  - 配置文件备份和恢复
  - YAML 格式验证

#### multi-gptload.ts - 多实例管理服务
- **职责**: 管理多个 gpt-load 实例的协调和分配
- **主要功能**:
  - 实例健康检查
  - 智能路由分配
  - 故障转移处理
  - 连通性测试

### 3. 自动化服务

#### model-sync.ts - 模型同步服务
- **职责**: 定期同步和更新模型配置
- **运行方式**: 后台定时任务
- **功能**: 保持配置一致性，自动发现新模型

#### channel-health.ts - 渠道健康监控
- **职责**: 监控各个渠道的健康状态
- **监控指标**: 响应时间、错误率、可用性
- **告警机制**: 自动故障检测和通知

#### channel-cleanup.ts - 渠道清理服务
- **职责**: 清理失效和冗余的渠道配置
- **清理策略**: 基于健康状态和使用频率

## 数据流

### 1. 站点配置流程

```
用户提交表单 → Express 服务器 → 参数验证 → 站点名称生成
     ↓
模型获取服务 → 第三方 AI 站点 `/v1/models` → 模型列表解析
     ↓
多实例管理 → 选择最佳 gpt-load 实例 → 健康检查
     ↓
gpt-load 交互 → 创建站点分组 → 创建模型分组 → 配置负载均衡
     ↓
uni-api 配置 → 更新 api.yaml → 配置验证 → 服务重载
```

### 2. 多实例路由决策

```
站点配置请求 → 获取所有实例状态 → 过滤健康实例
     ↓
按优先级排序 → 连通性测试 → 选择最佳实例
     ↓
分配站点到实例 → 记录映射关系 → 监控分配效果
```

### 3. 健康检查流程

```
定时器触发 → 遍历所有实例 → HTTP 健康检查
     ↓
记录响应状态 → 更新实例状态 → 故障检测
     ↓
触发故障转移 → 重新分配站点 → 通知管理员
```

## 分组架构设计

### 两层分组模式

```
第一层：站点分组 (Site Groups)
├── deepseek
│   ├── 上游地址: https://api.deepseek.com/v1
│   └── API 密钥: [sk-key1, sk-key2, ...]
├── openai
│   ├── 上游地址: https://api.openai.com/v1
│   └── API 密钥: [sk-key3, sk-key4, ...]
└── anthropic
    ├── 上游地址: https://api.anthropic.com/v1
    └── API 密钥: [sk-key5, sk-key6, ...]

第二层：模型分组 (Model Groups)
├── gpt-4
│   └── 上游: [openai 站点分组]
├── deepseek-chat
│   └── 上游: [deepseek 站点分组]
└── claude-3
    └── 上游: [anthropic 站点分组]
```

### 负载均衡策略

1. **站点级负载均衡**: 多个 API 密钥轮询使用
2. **模型级负载均衡**: 支持多站点提供同一模型
3. **实例级负载均衡**: 多个 gpt-load 实例分担负载

## 配置管理

### 环境配置优先级

```
.env.local (本地配置，最高优先级)
    ↓
.env (默认配置)
    ↓
环境变量 (系统级别)
    ↓
默认值 (代码中定义)
```

### 实例配置优先级

```
gptload-instances.local.json (本地配置)
    ↓
gptload-instances.json (生产配置)
    ↓
GPTLOAD_INSTANCES_FILE 环境变量指定的文件
```

## 安全设计

### 1. 认证和授权
- API 密钥安全存储
- gpt-load 实例 token 认证
- 配置文件权限控制

### 2. 输入验证
- URL 格式验证
- API 密钥格式检查
- 参数类型和长度限制

### 3. 错误处理
- 敏感信息过滤
- 详细错误日志记录
- 优雅的错误响应

## 性能优化

### 1. 连接池管理
- HTTP 客户端连接复用
- 合理的超时配置
- 连接数限制

### 2. 缓存策略
- 模型列表缓存
- 健康状态缓存
- 配置文件缓存

### 3. 异步处理
- 非阻塞 I/O 操作
- 并发请求处理
- 后台任务队列

## 监控和日志

### 1. 日志分类
- 操作日志: 用户操作记录
- 错误日志: 异常和错误信息
- 性能日志: 响应时间和资源使用

### 2. 健康监控
- 实例状态监控
- 渠道健康检查
- 资源使用监控

### 3. 告警机制
- 故障自动检测
- 关键指标阈值告警
- 服务恢复通知

## 扩展性设计

### 1. 插件化架构
- 模块化组件设计
- 标准化接口定义
- 动态加载机制

### 2. 多实例支持
- 水平扩展能力
- 负载分布机制
- 故障隔离设计

### 3. 协议适配
- 标准 OpenAI API 支持
- 自定义协议适配器
- 版本兼容性处理

## 部署架构

### 1. 单机部署
```
[Web UI] → [uni-load] → [gpt-load] → [uni-api] → [AI 站点]
```

### 2. 分布式部署
```
[Web UI] → [uni-load] → [gpt-load 集群] → [uni-api 集群] → [AI 站点群]
```

### 3. 容器化部署
```
[Docker Container: uni-load] ↔ [Docker Network] ↔ [Docker Container: gpt-load]
```